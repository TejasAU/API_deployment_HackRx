{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47023747-12c8-4517-9698-b644ae9a9c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d253a9-65ea-49ee-b497-3c0ab78ded26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset\n",
    "dataset_path = './dataset-doctor-bills/'\n",
    "forged_dir = os.path.join(dataset_path, 'forged')\n",
    "genuine_dir = os.path.join(dataset_path, 'genuine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "463465fb-baa9-429b-ae95-b7ffe3fed0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "window_size = (128, 128)  # Sliding window size (input size for the model)\n",
    "step_size = 64  # Step size for the sliding window\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5383f7d3-2a90-4dd6-955b-2f5adab28335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply sliding window without resizing the full image\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "    for y in range(0, image.shape[0] - windowSize[1] + 1, stepSize):\n",
    "        for x in range(0, image.shape[1] - windowSize[0] + 1, stepSize):\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd1e49d0-4f26-4072-b038-b150ab2d9b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset (load and extract patches)\n",
    "def load_and_extract_patches(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for label, folder in enumerate(['forged', 'genuine']):\n",
    "        folder_path = os.path.join(directory, folder)\n",
    "        for img_file in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_file)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is not None:\n",
    "                # Directly apply sliding window on the original high-resolution image\n",
    "                for (x, y, window) in sliding_window(image, stepSize=step_size, windowSize=window_size):\n",
    "                    if window.shape[0] == window_size[1] and window.shape[1] == window_size[0]:\n",
    "                        images.append(window)\n",
    "                        labels.append(label)  # 0 for forged, 1 for genuine\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4377d4e5-34bf-40b6-ac3a-65ec1d817e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "X, y = load_and_extract_patches(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45cea1c0-f1ef-40bd-8c26-3f3793663f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "# Custom generator to load images and extract patches on the fly\n",
    "class PatchDataGenerator(Sequence):\n",
    "    def __init__(self, image_paths, labels, batch_size, window_size=(128, 128), step_size=64):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.window_size = window_size\n",
    "        self.step_size = step_size\n",
    "        self.indexes = np.arange(len(self.image_paths))\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Total number of batches per epoch\n",
    "        return int(np.floor(len(self.image_paths) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indexes\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        \n",
    "        # Load and preprocess a batch of images\n",
    "        images, labels = self.__data_generation(batch_indexes)\n",
    "        \n",
    "        return np.array(images), np.array(labels)\n",
    "    \n",
    "    def __data_generation(self, batch_indexes):\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in batch_indexes:\n",
    "            img_path = self.image_paths[i]\n",
    "            image = cv2.imread(img_path)\n",
    "            label = self.labels[i]  # 0 for forged, 1 for genuine\n",
    "            if image is not None:\n",
    "                # Apply sliding window\n",
    "                for (x, y, window) in sliding_window(image, stepSize=self.step_size, windowSize=self.window_size):\n",
    "                    if window.shape[0] == self.window_size[1] and window.shape[1] == self.window_size[0]:\n",
    "                        window = window / 255.0  # Normalize\n",
    "                        images.append(window)\n",
    "                        labels.append(label)\n",
    "        return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "021b6f87-a9e2-45dc-b666-fbb1261d7ab4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Split the dataset into training and validation sets\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m train_image_paths, val_image_paths, train_labels, val_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m(\n\u001b[0;32m     20\u001b[0m     image_paths, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m  \u001b[38;5;66;03m# 20% validation data\u001b[39;00m\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Create training generator\u001b[39;00m\n\u001b[0;32m     24\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m PatchDataGenerator(train_image_paths, train_labels, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# Define dataset path\n",
    "dataset_path = 'dataset-doctor-bills'  # Adjust as necessary\n",
    "\n",
    "# Get image paths and labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for label, folder in enumerate(['forged', 'genuine']):\n",
    "    folder_path = os.path.join(dataset_path, folder)\n",
    "    for img_file in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_file)\n",
    "        image_paths.append(img_path)\n",
    "        labels.append(label)  # 0 for forged, 1 for genuine\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 16\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_image_paths, val_image_paths, train_labels, val_labels = train_test_split(\n",
    "    image_paths, labels, test_size=0.2, random_state=42  # 20% validation data\n",
    ")\n",
    "\n",
    "# Create training generator\n",
    "train_generator = PatchDataGenerator(train_image_paths, train_labels, batch_size=batch_size)\n",
    "\n",
    "# Create validation generator\n",
    "val_generator = PatchDataGenerator(val_image_paths, val_labels, batch_size=batch_size)\n",
    "\n",
    "# Define the ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the ResNet50 layers (optional)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "learning_rate = 0.001  # Ensure this is defined\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the generators\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d6022a-bba9-4a27-8ff3-854c1c27dd69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
